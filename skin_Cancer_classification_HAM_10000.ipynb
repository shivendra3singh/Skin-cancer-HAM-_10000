{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "skin Cancer classification HAM_10000.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "_uuid": "2852ee80cbebe70f1acb26561531ca5b91f490e4",
        "id": "OG9WMA55Ff1A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Imagine **\n",
        "\n",
        "You wake up and find a frightening mark on your skin so you go to the doctor’s office to get it checked up. They say it’s fine so you go home and don’t worry about it for a couple months, but then you have a throbbing pain from that spot — it looks ugly and menacing now. It has developed into a malignant tumour as a result of your doctor’s misdiagnosis. The prevalence of misdiagnosis is scary. A study has shown that over 1 in 20 American adults have been misdiagnosed in that past and over half of these are harmful. A lot of skin lesions can be pretty much harmless but others can be life-threatening. It’s super important that these tumours are discovered right away, this is when it is the easiest to treat them."
      ]
    },
    {
      "metadata": {
        "id": "BwNvge2ihMK9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Skin Cancer Classifier**\n",
        "\n",
        "A predictive model that uses the HAM10000 dataset, trained on two architectures to compare the best performance ,MobileNet and Resnet50 to classify skin lesions into seven categories. We have trained the model locally using native Keras.Training process is documented and coded here \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "371731306c3e504b191979706e826c247def88dc",
        "id": "sJlUd8Z4Ff1E",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import io\n",
        "from google.colab import files\n",
        "\n",
        "from numpy.random import seed\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(101)\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import itertools\n",
        "import shutil\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.metrics import classification_report\n",
        "import tensorflow\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "086162161ba405b800863e7d545b5917e5205984",
        "id": "CY-cirtdFf1T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Loading files in Colab and creating  directory structure"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d24ef21f9f2359b8bf6b3e7a0b8ab5a43daaf566",
        "id": "iEBmuR-IFf1W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I5WoUv7TF9Z6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = zipfile.ZipFile(io.BytesIO(uploaded['Cancer_Data.zip']), 'r')\n",
        "data.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "268503398ef61904e05a2c0b0667d589f08a19a8",
        "id": "2RkGV29iFf1b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Read the metadata\n",
        "df_data = pd.read_csv('Cancer_Data/HAM10000_metadata.csv')\n",
        "# Get a list of images in each of the two folders\n",
        "HAM_1 = os.listdir('Cancer_Data/ham10000_images_part_1')\n",
        "HAM_2 = os.listdir('Cancer_Data/ham10000_images_part_2')\n",
        "\n",
        "# Skin Cancer Dataset Preprocessing\n",
        "\n",
        "# Training file directory\n",
        "os.mkdir(os.path.join('Cancer_Data', 'training'))\n",
        "\n",
        "# Validation file directory\n",
        "os.mkdir(os.path.join('Cancer_Data', 'Validation'))\n",
        "# Create new folders in the training directory for each of the classes\n",
        "\n",
        "os.mkdir(os.path.join('Cancer_Data/training', 'nv'))\n",
        "os.mkdir(os.path.join('Cancer_Data/training', 'mel'))\n",
        "os.mkdir(os.path.join('Cancer_Data/training', 'bkl'))\n",
        "os.mkdir(os.path.join('Cancer_Data/training', 'bcc'))\n",
        "os.mkdir(os.path.join('Cancer_Data/training', 'akiec'))\n",
        "os.mkdir(os.path.join('Cancer_Data/training', 'vasc'))\n",
        "os.mkdir(os.path.join('Cancer_Data/training', 'df'))\n",
        "\n",
        "# Create new folders in the validation directory for each of the classes\n",
        "os.mkdir(os.path.join('Cancer_Data/Validation', 'nv'))\n",
        "os.mkdir(os.path.join('Cancer_Data/Validation', 'mel'))\n",
        "os.mkdir(os.path.join('Cancer_Data/Validation', 'bkl'))\n",
        "os.mkdir(os.path.join('Cancer_Data/Validation', 'bcc'))\n",
        "os.mkdir(os.path.join('Cancer_Data/Validation', 'akiec'))\n",
        "os.mkdir(os.path.join('Cancer_Data/Validation', 'vasc'))\n",
        "os.mkdir(os.path.join('Cancer_Data/Validation', 'df'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c46ea5967e095d31dcf144b6f57f0343878fa432",
        "id": "0a7q6sH9Ff1f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Creating Validation stratified dataset"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "53e4b7b152ed831a7d7516156ac300c0e6985ffc",
        "id": "FAzVk2c-Ff1g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this will tell us how many images are associated with each lesion_id and filter out lesion_id's that have only one image associated with it\n",
        "df = df_data.groupby('lesion_id').count()\n",
        "df = df[df['image_id'] == 1]\n",
        "df.reset_index(inplace=True)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "N_mtYVW1LH0h",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Checking duplicates"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "24720fe3ea9f2f4b571abd09ecfbb931d6429852",
        "id": "siYjwt0ZFf1j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def duplicates(x):\n",
        "    unique_list = list(df['lesion_id'])\n",
        "    if x in unique_list:\n",
        "        return 'no_duplicates'\n",
        "    else:\n",
        "        return 'has_duplicates'\n",
        "    \n",
        "# create a new colum that is a copy of the lesion_id column\n",
        "df_data['duplicates'] = df_data['lesion_id']\n",
        "# apply the function to this new column\n",
        "df_data['duplicates'] = df_data['duplicates'].apply(duplicates)\n",
        "# now we filter out images that don't have duplicates\n",
        "df = df_data[df_data['duplicates'] == 'no_duplicates']\n",
        "_, df_val = train_test_split(df, test_size=0.17, random_state=101, stratify=df['dx'])\n",
        "\n",
        "def Validation_subset(x):\n",
        "    if str(x) in list(df_val['image_id']):\n",
        "        return 'validation'\n",
        "    else:\n",
        "        return 'training'\n",
        "df_data['train_or_val'] = df_data['image_id']\n",
        "# apply the function to this new column\n",
        "df_data['train_or_val'] = df_data['train_or_val'].apply(Validation_subset)\n",
        "   \n",
        "# filter out train rows\n",
        "df_train = df_data[df_data['train_or_val'] == 'training']\n",
        "print(len(df_train))\n",
        "print(len(df_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "08c5e12fcef2da5f49267a6b82161b2c52c2b20a",
        "id": "-od5ZHRBFf16",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Train  subset without validation images "
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4acee2b7879762e50b52df118a9b691515fe7ac0",
        "id": "71ZvdxlYFf2G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Set the image_id as the index in df_data\n",
        "df_data.set_index('image_id', inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "eca02fbf066c8124d0cb465295bbd2593f5f045a",
        "id": "-QCW3R0RFf2L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_data.set_index('image_id', inplace=True)\n",
        "# train and validation images \n",
        "\n",
        "for image in list(df_train['image_id']):\n",
        "    Im_name = image + '.jpg'\n",
        "    label = df_data.loc[image,'dx']\n",
        "    if Im_name in HAM_1:\n",
        "        src = os.path.join('Cancer_Data/ham10000_images_part_1', Im_name)\n",
        "        dst = os.path.join(training, label, Im_name)\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "    if Im_name in HAM_2:\n",
        "        src = os.path.join('Cancer_Data/ham10000_images_part_2', Im_name)\n",
        "        dst = os.path.join(training, label, Im_name)\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "\n",
        "\n",
        "for image in list(df_val['image_id']):\n",
        "    Im_name = image + '.jpg'\n",
        "    label = df_data.loc[image,'dx']\n",
        "    \n",
        "    if Im_name in HAM_1:\n",
        "        # source path to image\n",
        "        src = os.path.join('Cancer_Data/ham10000_images_part_1', Im_name)\n",
        "        # destination path to image\n",
        "        dst = os.path.join(Validation, label, Im_name)\n",
        "        # copy the image from the source to the destination\n",
        "        shutil.copyfile(src, dst)\n",
        "\n",
        "    if Im_name in HAM_2:\n",
        "        # source path to image\n",
        "        src = os.path.join('Cancer_Data/ham10000_images_part_2', Im_name)\n",
        "        # destination path to image\n",
        "        dst = os.path.join(Validation, label, Im_name)\n",
        "        # copy the image from the source to the destination\n",
        "        shutil.copyfile(src, dst)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "cebcb5242ff542efb03be5086bf3796bea70c591",
        "id": "zQn64K7KFf2Y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Augmentation"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8fe970d74e9d5a284420af4ad37d8aae89dc1c15",
        "id": "nuqnrFfOFf2a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class_list = ['mel','bkl','bcc','akiec','vasc','df']\n",
        "\n",
        "for item in class_list:\n",
        "    aug_dir = 'aug_dir'\n",
        "    os.mkdir(aug_dir)\n",
        "    img_dir = os.path.join(aug_dir, 'img_dir')\n",
        "    os.mkdir(img_dir)\n",
        "    img_class = item\n",
        "    img_list = os.listdir('Cancer_Data/training/' + img_class)\n",
        "    for Im_name in img_list:\n",
        "            src = os.path.join('Cancer_Data/training/' + img_class, Im_name)\n",
        "            dst = os.path.join(img_dir, Im_name)\n",
        "            # copy the image from the source to the destination\n",
        "            shutil.copyfile(src, dst)\n",
        "    path = aug_dir\n",
        "    save_path = 'Cancer_Data/training/' + img_class\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=180,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1,\n",
        "        zoom_range=0.1,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True,\n",
        "        #brightness_range=(0.9,1.1),\n",
        "        fill_mode='nearest')\n",
        "\n",
        "    batch_size = 50\n",
        "\n",
        "    aug_datagen = datagen.flow_from_directory(path,save_to_dir=save_path,save_format='jpg',target_size=(224,224),batch_size=batch_size)\n",
        "    \n",
        "    num_aug_images_wanted = 6000 \n",
        "    num_files = len(os.listdir(img_dir))\n",
        "    num_batches = int(np.ceil((num_aug_images_wanted-num_files)/batch_size))\n",
        "    for i in range(0,num_batches):\n",
        "\n",
        "        imgs, labels = next(aug_datagen)\n",
        "    shutil.rmtree('aug_dir')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "32dad10b7c104d2baa972da8cbadc7d6038af05c",
        "id": "lNGQxlwdFf2r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Generators settings"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "d0e5aede7139196b0d4e1344b278e7621f005550",
        "id": "ZXWBIKhRFf2w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "datagen = ImageDataGenerator(\n",
        "    preprocessing_function= \\\n",
        "    tensorflow.keras.applications.mobilenet.preprocess_input)\n",
        "\n",
        "train_batches = datagen.flow_from_directory('Cancer_Data/training',target_size=(224,224),batch_size=10)\n",
        "\n",
        "valid_batches = datagen.flow_from_directory('Cancer_Data/Validation',target_size=(224,224),batch_size=10)\n",
        "\n",
        "# Note: shuffle=False causes the test dataset to not be shuffled\n",
        "test_batches = datagen.flow_from_directory('Cancer_Data/Validation',target_size=(224,224),batch_size=1,shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "8ee4ee41f1b16083bd9fc20ee9dec40acccc97dd",
        "id": "WdIr5DEqFf20",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Modeling based on two architectures ,modification is done on  classification layers and dense\n",
        "\n",
        "1. Mobilenet                     2.Resnet50\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "o_Y7SvO-TcM9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Mobilenet Architecture modification"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ad582cb8ea0ca2d563fc367aa89b7edfafc1a57f",
        "id": "Srg4ATfnFf21",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "mobile = tensorflow.keras.applications.mobilenet.MobileNet()\n",
        "x = mobile.layers[-6].output\n",
        "x = Dropout(0.25)(x)\n",
        "predictions = Dense(7, activation='softmax')(x)\n",
        "model1 = Model(inputs=mobile.input, outputs=predictions)\n",
        "# We need to choose how many layers we actually want to be trained.\n",
        "for layer in model1.layers[:-23]:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vEjKVkShjNpH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Resnet Architecture"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a9d74e44630c3d07a596460c8fbfda3ae7cae1e9",
        "id": "GWzYfjkUFf3w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "2c610dcc-1d9b-4859-fa5c-10320a0766ed"
      },
      "cell_type": "code",
      "source": [
        "Res_model = tensorflow.keras.applications.ResNet50()\n",
        "x = Res_model.layers[-3].output\n",
        "x = Dropout(0.25)(x)\n",
        "predictions = Dense(7, activation='softmax')(x)\n",
        "model2 = Model(inputs=Res_model.input, outputs=predictions)\n",
        "# We need to choose how many layers we actually want to be trained.\n",
        "for layer in model2.layers[:-23]:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "102858752/102853048 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "13cf63a53e5195cb8a9725d2506c71108bc478b9",
        "id": "C5dWLg6IFf33",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train the Model"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "915f30a4f5ad369713bcb8e3bfa438219d6c8ef7",
        "id": "KLfn6CJ4Ff36",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.metrics import categorical_accuracy, top_k_categorical_accuracy\n",
        "\n",
        "def top_3_accuracy(y_true, y_pred):\n",
        "    return top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
        "\n",
        "def top_2_accuracy(y_true, y_pred):\n",
        "    return top_k_categorical_accuracy(y_true, y_pred, k=2)\n",
        "  \n",
        "  \n",
        "model1.compile(Adam(lr=0.01), loss='categorical_crossentropy', \n",
        "              metrics=[categorical_accuracy, top_2_accuracy, top_3_accuracy])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n_24DzHNUMiu",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Weights assignment based on classes"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3001857c9a3c2b15c2343627e340eb1ae858fae9",
        "id": "EH2AoHCxFf4a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class_weights={\n",
        "    0: 1.0, \n",
        "    1: 1.0,\n",
        "    2: 1.0,\n",
        "    3: 1.0,\n",
        "    4: 3.0,\n",
        "    5: 1.0,\n",
        "    6: 1.0,\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4a5e3bc3cf44f1d4326c34ad880a302ba082e9d5",
        "scrolled": false,
        "_kg_hide-output": true,
        "id": "JpZ_jZ6ZFf4k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "d5f049f5-7979-4121-d884-2ea70697c63d"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "filepath = \"model.h5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_top_3_accuracy', verbose=1, \n",
        "                             save_best_only=True, mode='max')\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_top_3_accuracy', factor=0.5, patience=2, \n",
        "                                   verbose=1, mode='max', min_lr=0.00001)\n",
        "                              \n",
        "                              \n",
        "callbacks_list = [checkpoint, reduce_lr]\n",
        "\n",
        "history = model1.fit_generator(train_batches, steps_per_epoch=train_steps, \n",
        "                              class_weight=class_weights,\n",
        "                    validation_data=valid_batches,\n",
        "                    validation_steps=val_steps,\n",
        "                    epochs=30, verbose=1,\n",
        "                   callbacks=callbacks_list)\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-8047b1e5f159>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mcallbacks_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_lr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m history = model1.fit_generator(train_batches, steps_per_epoch=train_steps, \n\u001b[0m\u001b[1;32m     13\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_batches\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_batches' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "c3e43e3f2943db4be9d75831fe23661ae9deb44b",
        "id": "KS3pJeTtFf4q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###Model Evaluation"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "68603a5e8cb5e507db95074a07b552a61fa48e11",
        "id": "WngKpnutFf4x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "val_loss, val_cat_acc, val_top_2_acc, val_top_3_acc = \\\n",
        "model.evaluate_generator(test_batches, \n",
        "                        steps=len(df_val))\n",
        "\n",
        "print('val_loss:', val_loss)\n",
        "print('val_cat_acc:', val_cat_acc)\n",
        "print('val_top_2_acc:', val_top_2_acc)\n",
        "print('val_top_3_acc:', val_top_3_acc)\n",
        "\n",
        "model.load_weights('model.h5')\n",
        "\n",
        "val_loss, val_cat_acc, val_top_2_acc, val_top_3_acc = \\\n",
        "model.evaluate_generator(test_batches, \n",
        "                        steps=len(df_val))\n",
        "\n",
        "print('val_loss:', val_loss)\n",
        "print('val_cat_acc:', val_cat_acc)\n",
        "print('val_top_2_acc:', val_top_2_acc)\n",
        "print('val_top_3_acc:', val_top_3_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4204e4056c8d12c1fee72b97912879cad4ee483f",
        "id": "H_j5Sb-0Ff5C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Create a Confusion Matrix"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "7cfd9bdbbd27e27d9c5de7c6593527686445ea89",
        "id": "i7huRUftFf5m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Get the labels of the test images.\n",
        "test_labels = test_batches.classes\n",
        "# make a prediction\n",
        "predictions = model.predict_generator(test_batches, steps=len(df_val), verbose=1)\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.tight_layout()\n",
        "\n",
        "# argmax returns the index of the max value in a row\n",
        "cm = confusion_matrix(test_labels, predictions.argmax(axis=1))\n",
        "cm_plot_labels = ['akiec', 'bcc', 'bkl', 'df', 'mel','nv', 'vasc']\n",
        "plot_confusion_matrix(cm, cm_plot_labels, title='Confusion Matrix')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "571f3f23d58daa03ec3fbf9207363063b2a63373",
        "id": "K-Y_7BXOFf57",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Classification Report"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ebc31a49c8e8ab5d1305e46a7d638e0da326da8b",
        "id": "3-Y6qnPcFf57",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred = np.argmax(predictions, axis=1)\n",
        "y_true = test_batches.classes\n",
        "report = classification_report(y_true, y_pred, target_names=cm_plot_labels)\n",
        "print(report)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CQFU-kx8kn0J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "model's accuracy for mobilenet score settles around 82%, this is mainly due to a small and unbalanced dataset.It can be boosted more using augmentation techniques but due to resource constraints I tried above methodology and results are found good."
      ]
    }
  ]
}